# ğŸ¤ Whisper-Medium Fine-tuned for Korean ASR

í•œêµ­ì–´ ìŒì„± ì¸ì‹ì„ ìœ„í•´ OpenAI Whisper-Medium ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

## ğŸ“Š ëª¨ë¸ ì •ë³´

- **Base Model**: OpenAI Whisper-Medium
- **Language**: Korean
- **Sample Rate**: 16kHz
- **Training Strategy**: 2-Stage Fine-tuning
  - Stage 1: ëŒ€ëŸ‰ ë°ì´í„° ê¸°ë³¸ í•™ìŠµ
  - Stage 2: íƒ€ê²Ÿ ë„ë©”ì¸ ì ì‘

## ğŸ¯ ì„±ëŠ¥

| Metric | Value |
|--------|-------|
| CER    | X.XX% |
| WER    | X.XX% |

*ê²€ì¦ ë°ì´í„° XXXê°œ ìƒ˜í”Œ ê¸°ì¤€*

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ì„¤ì¹˜
```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/yourusername/asr_certificate_2025.git
cd asr_certificate_2025

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### ì¶”ë¡  ì˜ˆì‹œ
```python
from transformers import WhisperProcessor, WhisperForConditionalGeneration
import librosa

# ëª¨ë¸ ë¡œë“œ
model = WhisperForConditionalGeneration.from_pretrained("./model")
processor = WhisperProcessor.from_pretrained("./model")

# ì˜¤ë””ì˜¤ ë¡œë“œ
audio, sr = librosa.load("audio.wav", sr=16000)

# ì¶”ë¡ 
inputs = processor(audio, sampling_rate=16000, return_tensors="pt")
predicted_ids = model.generate(inputs["input_features"])
transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]

print(transcription)
```

## ğŸ§ª ëª¨ë¸ ê²€ì¦

### ì„¤ì •

`config/config.yml` íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ ê²€ì¦ ë°ì´í„° ê²½ë¡œ ì„¤ì •:
```yaml
validation:
  data_dir: "./data/test/audio"
  manifest: "./data/test/manifest.json"
  model_path: "./model"
  output_dir: "./results"
```

### ì‹¤í–‰
```bash
python validator.py
```

### ì¶œë ¥

- ì—‘ì…€ íŒŒì¼: `results/validate_YYYYMMDD_HHMMSS_{ìƒ˜í”Œìˆ˜}.xlsx`
- ì»¬ëŸ¼: íŒŒì¼ëª…, ì •ë‹µ, ì˜ˆì¸¡, CER, ì¶”ë¡ ì‹œê°„(ì´ˆ)

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°
```
asr_certificate_2025/
â”œâ”€â”€ model/                      # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ (Git LFS)
â”‚   â”œâ”€â”€ model.safetensors      # ëª¨ë¸ ê°€ì¤‘ì¹˜
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/                        # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â””â”€â”€ augmentor.py           # ìŒì„± ì¦ê°• ëª¨ë“ˆ
â”œâ”€â”€ config/                     # ì„¤ì • íŒŒì¼
â”‚   â””â”€â”€ config.yml             # ê²€ì¦ ì„¤ì •
â”œâ”€â”€ data/                       # ë°ì´í„° (ë¡œì»¬ ì „ìš©)
â”‚   â””â”€â”€ test/                  # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â”œâ”€â”€ validator.py                # ëª¨ë¸ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt            # ì˜ì¡´ì„±
â””â”€â”€ README.md
```

## ğŸ“¦ ë°ì´í„°ì…‹

### í•™ìŠµ ë°ì´í„°
- ë‰´ìŠ¤(35k), ì»¤ë¨¸ìŠ¤(13.5k), ê°•ì˜/ìƒë‹´/ì „í™”/..(9.6k)
- í˜•ì‹: MP3/WAV, 16kHz

*ì €ì‘ê¶Œ ë¬¸ì œë¡œ í•™ìŠµ ë°ì´í„°ëŠ” ê³µê°œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.*

### Manifest í˜•ì‹
```json
[
  {
    "audio": "audio_001.wav",
    "text": "ì „ì‚¬ëœ í…ìŠ¤íŠ¸"
  },
  {
    "audio": "audio_002.wav",
    "text": "ë‘ ë²ˆì§¸ ìƒ˜í”Œ"
  }
]
```

## ğŸ”§ ìŒì„± ì¦ê°•

`src/augmentor.py`ëŠ” ë‹¤ìŒ ì¦ê°• ê¸°ë²•ì„ ì§€ì›í•©ë‹ˆë‹¤:

- **Noise Addition**: ëœë¤ ë…¸ì´ì¦ˆ ì¶”ê°€
- **Pitch Shift**: ìŒë†’ì´ ë³€ê²½
- **Speed Change**: ì†ë„ ì¡°ì ˆ
- **Gain**: ë³¼ë¥¨ ì¡°ì •
- **Low/High Pass Filter**: ì£¼íŒŒìˆ˜ í•„í„°ë§
- **Phase Inversion**: ìœ„ìƒ ë°˜ì „

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from src.augmentor import HybridAudioAugmentor

augmentor = HybridAudioAugmentor(sr=16000)
results = augmentor.run_augmentation("input.wav", "./output_dir")
```